package parser;

import java.io.IOException;
import java.util.ArrayList;
import java.util.LinkedList;
import java.util.List;

import source.ErrorHandler;
import source.Errors;
import source.Position;
import source.Severity;
import source.Source;
import syms.SymEntry;
import syms.SymbolTable;
import syms.Type;
import tree.BinaryOperator;
import tree.ConstExp;
import tree.DeclNode;
import tree.ExpNode;
import tree.StatementNode;
import tree.Tree;
import tree.UnaryOperator;

/**
 * class Parser - PL0 syntax parser implemented by recursive descent
 * @version $Id: Parser.java 6 2013-02-22 05:25:09Z ianh $ 
 *
 *  The syntax analyser recognises a PL0 program according to the following
 *  syntax specification using a recursive descent parser. It constructs
 *  the corresponding abstract syntax tree and skeleton symbol table.
 *  PL0 EBNF Grammar:
 *  Program -> Block ENDOFFILE
 *  Block -> { Declaration } CompoundStatement
 *  Declaration -> ConstDefList | TypeDefList | VarDeclList | ProcedureDef
 *  ConstDefList -> KW_CONST ConstDef { ConstDef }
 *  ConstDef -> IDENTIFIER EQUALS Constant SEMICOLON
 *  Constant -> NUMBER | IDENTIFIER | MINUS Constant
 *  TypeDefList -> KW_TYPE TypeDef { TypeDef }
 *  TypeDef -> IDENTIFIER EQUALS Type SEMICOLON
 *  Type -> IDENTIFIER | SubrangeType
 *  TypeIdentifier -> IDENTIFIER
 *  SubrangeType -> Constant RANGE Constant
 *  VarDeclList -> KW_VAR VarDecl { VarDecl }
 *  VarDecl -> IDENTIFIER COLON TypeIdentifier SEMICOLON
 *  ProcedureDef -> ProcedureHead EQUALS Block SEMICOLON
 *  ProcedureHead -> KW_PROCEDURE IDENTIFIER LPAREN RPAREN
 *  CompoundStatement -> KW_BEGIN StatementList KW_END
 *  StatementList -> Statement { SEMICOLON Statement }
 *  Statement -> WhileStatement | IfStatement | CallStatement | Assignment | 
 *               ReadStatement | WriteStatement | CompoundStatement
 *  Assignment -> LValue ASSIGN Condition
 *  WhileStatement -> KW_WHILE Condition KW_DO Statement
 *  IfStatement -> KW_IF Condition KW_THEN Statement KW_ELSE Statement
 *  CallStatement -> KW_CALL IDENTIFIER LPAREN RPAREN
 *  ReadStatement -> KW_READ LValue
 *  WriteStatement -> KW_WRITE Exp
 *  Condition -> Exp [ RelOp Exp ]
 *  RelOp   -> EQUALS | NEQUALS | LEQUALS | LESS | GREATER | GEQUALS
 *  Exp     -> [ PLUS | MINUS ] Term   { ( PLUS | MINUS ) Term }
 *  Term    -> Factor { ( TIMES | DIVIDE ) Factor }
 *  Factor  -> LPAREN Condition RPAREN | NUMBER | LValue
 *  LValue -> IDENTIFIER
 *
 *  where any constructs not defined by the above productions
 *  are terminal symbols generated by the lexical analyser.
 */
public class Parser {

/******************************* Constants **********************************/

    /* Starting sets for various parsing rules */
    /** Token set with just end of file token */
    private final static TokenSet EOF_SET =
        new TokenSet( Token.EOF );
    /** Set of tokens that may start an LValue. */
    private final static TokenSet LVALUE_START_SET =
        new TokenSet( Token.IDENTIFIER );
    /** Set of tokens that may start an Assignment. */
    private final static TokenSet ASSIGNMENT_START_SET =
    	LVALUE_START_SET;
    /** Set of tokens that may start a Statement. */
    private final static TokenSet STATEMENT_START_SET =
        LVALUE_START_SET.union( Token.KW_WHILE, Token.KW_IF,
          Token.KW_READ, Token.KW_WRITE,
          Token.KW_CALL, Token.KW_BEGIN, Token.KW_SKIP, Token.KW_DO );
    /** Set of tokens that may start a Declaration. */
    private final static TokenSet DECLARATION_START_SET =
        new TokenSet( Token.KW_CONST, Token.KW_TYPE, Token.KW_VAR, 
          Token.KW_PROCEDURE );
    /** Set of tokens that may start a Block. */
    private final static TokenSet BLOCK_START_SET =
        DECLARATION_START_SET.union( Token.KW_BEGIN );
    /** Set of tokens that may start a Constant. */
    private final static TokenSet CONSTANT_START_SET = 
        new TokenSet( Token.IDENTIFIER, Token.NUMBER, Token.MINUS );
    /** Set of tokens that may start a TypeStructure. */
    private final static TokenSet TYPE_START_SET = 
        CONSTANT_START_SET;
    /** Set of tokens that may start a Factor. */
    private final static TokenSet FACTOR_START_SET = 
        LVALUE_START_SET.union( Token.NUMBER, Token.LPAREN );
    /** Set of tokens that may start a Term. */
    private final static TokenSet TERM_START_SET = 
        FACTOR_START_SET;
    /** Set of tokens that may start an Expression. */
    private final static TokenSet EXP_START_SET =
        TERM_START_SET.union( Token.PLUS, Token.MINUS );
    /** Set of tokens that may start a Condition. */
    private final static TokenSet CONDITION_START_SET =
        EXP_START_SET;

    /* Operation sets for relations, expressions, and terms */
    /** Set of tokens representing relational operators. */
    private final static TokenSet REL_OPS_SET =
        new TokenSet( Token.EQUALS, Token.NEQUALS, Token.LESS, Token.GREATER,
          Token.LEQUALS, Token.GEQUALS );
    /** Set of tokens for expression operators. */
    private final static TokenSet EXP_OPS_SET =
        new TokenSet( Token.PLUS, Token.MINUS );
    /** Set of tokens for term operators. */
    private final static TokenSet TERM_OPS_SET =
        new TokenSet( Token.TIMES, Token.DIVIDE );
    
    /*************************** Instance Variables ************************/
    /** The current token */
    private LexicalToken token;
    /** The lexical analyser */
    private Scanner lex;
    /** Source file handler */
    private Source source;
    /** The object to report errors to */
    private Errors errors = ErrorHandler.getErrorHandler();
    /** The symbol table */
    private SymbolTable symtab;
    /** Control verbose parser debugging output */
    private boolean debugParse;
    /** Track nesting depth in parsing calls */
    private int debugLevel = 0;
    
    /****************************** Constructor ****************************/
    /** Construct a parser with the given lexer 
     * @param lex Scanner object for performing lexical analysis
     * @requires lex != null;
     */
    public Parser( Scanner lex, boolean debugParse ) throws IOException {
        this.lex = lex;
        this.debugParse = debugParse;
        this.source = lex.getSourceHandler();
        /** Set up a symbol table. 
         * The initial value includes the predefined scope.
         */
        this.symtab = new SymbolTable();
        token = lex.getNextToken(); /* Initialise look-ahead */
    }
    /***************************** Public Methods ***************************/
    /** Parse the input stream. 
     *  @return constructed tree only if the stream was parsed correctly.
     */
    public Tree.ProgramNode parse() {
        Tree.ProgramNode root =  parseProgram();
        return root;
    }

    /**************************** Support Methods ***************************/
    /** Get the next token and place it in the variable token. 
     * Declare a fatal error on IOException
     * @requires token != Token.EOF;
     */
    private void nextToken() {
        try {
            token = lex.getNextToken();
        } catch( IOException e ) {
            errors.errorMessage( "Caught IOException " + e, Severity.FATAL,
                                Position.NO_POSITION );
            /* Never returns, but just in case: */
            System.exit(1);
        }
    }
    /** Match a token equal to that expected.
     * If the current token is the expected token, it is skipped,
     * otherwise an error is reported and error recovery attempted.
     * For the error recovery, if the current token can follow the expected
     * token, then it is assumed that the expected token was omitted and
     * no error recovery is necessary, otherwise the current token is skipped.
     * If the current token is skipped then the next token may be the
     * expected token, if so, it is matched.
     * @param expected token expected next in the input stream.
     * @param follows set of tokens expected to follow the expected token.
     * @requires follows is nonempty
     */
    private void match( Token expected, TokenSet follows ) {
        if( token.isMatch( expected ) ) {
            match( expected );
        } else {
            debugMessage( "Parse error, expecting '" + expected + "'" );
            error( "Parse error, expecting '" + expected + "'" );
            /* If the current token may follow the expected token then
             * treat it as though the expected token was missing and
             * do no further error recovery.
             */ 
            if( ! token.isIn( follows ) &&
                    !token.isMatch( Token.EOF ) ) {
                // Skip the erroneous token
                debugMessage( "Skipping " + tokenString( token ) );
                nextToken();
                /* If after skipping, the (new) token is not the expected 
                 * token we do no further error recovery (in match at least).
                 */
                if( token.isMatch( expected ) ) {
                    /* If after skipping the erroneous token we find 
                     * the expected token we match it
                     */
                    match( expected );
                }
            }
        }
    }
    /** Match when follow set is a single token
     * @param follows single token that may follow
     */
    private void match( Token expected, Token follows ) {
        match( expected, new TokenSet( follows ) );
    }
    /** Match if token is expected, 
     * otherwise there is an error in the compiler */
    private void match( Token expected ) {
        pl0_assert( token.isMatch( expected ), "Match assertion failed" );
        debugMessage( "Matched " + tokenString( token ) );
        nextToken();
    }
    /** Return token name and position as debug string */
    private String tokenString( LexicalToken token ) {
        return "'" + token.toString() + "'" + 
            " at line " + source.getLineNumber( token.getPosn() ) +
            " column " + source.offset( token.getPosn() );
    }
    /** Skip tokens until one is found which is in the parameter set find. 
     * Used for error recovery. 
     * @param find set of tokens - skip until one found in this set
     * @requires find.contains( Token.EOF ); 
     */
    private void skipTo( TokenSet find ) {
        while( ! token.isIn( find ) ) {
            debugMessage( "Skipping " + tokenString( token ) );
            nextToken();
        }
    }
    /** Begin a parsing rule. 
     * Ensure that the next token is in the set of tokens expected 
     * at the start of a grammar rule (or equal to the expected token 
     * for the second variant of this method, below). 
     * An error is reported if it isn't.
     * @param rule name of the rule for use in error messages
     * @param expected set of tokens expected at start of rule
     * @param recoverSet set of tokens to recover at on a syntax error
     * @return true iff an expected token was (eventually) found.
     */
    private boolean beginRule( String rule, TokenSet expected,
            TokenSet recoverSet ) {
        debugMessage( "Begin parse " + rule + " recover on " + recoverSet );
        debugLevel++;
        if( ! token.isIn( expected ) ) {
            error( expected + " expected at start of " + rule );
            debugMessage( expected + " expected at start of " + rule );
            skipTo( recoverSet.union( expected ) );
            if( !token.isIn( expected ) ) {
                debugLevel--;
                return false;
            }
        }
        return true;
    }
    /** Begin a parsing rule. 
     * Same as above, except that expected is a single token.
     * @param expected token expected at start of rule
     */
    private boolean beginRule( String rule, Token expected,
            TokenSet recoverSet) {
        return beginRule( rule, new TokenSet( expected ), recoverSet );
    }
    /** Version of beginRule when failure indicates that there
     * is an error in the PL0 compiler.
     */
    private void beginRule( String rule, TokenSet expected ) {
        debugMessage( "Begin parse " + rule );
        debugLevel++;
        if( ! token.isIn( expected ) ) {
            fatal( expected + " expected at start of " + rule );
            // doesn't return from fatal error
        }
        return;
    }
    /** Version of beginRule when failure indicates that there
     * is an error in the PL0 compiler.
     * @param expected token expected at start of rule
     */
    private void beginRule( String rule, Token expected ) {
        beginRule( rule, new TokenSet( expected ) );
        return;
    }
    /** End a parsing rule.
     * Ensure that the current token is a member of the recovery set 
     * (i.e., something which an ancestor rule is expecting).
     * @param rule name of the rule for use in error messages
     * @param recoverSet set of tokens to recover at on a syntax error
     * @requires recoverSet.contains( Token.EOF);
     */
    private void endRule( String rule, TokenSet recoverSet ) {
        if( ! token.isIn( recoverSet ) ) {
            error( "Illegal symbol '" + token + "' following " + rule );
            debugMessage( "Illegal symbol '" + token + "' following " + rule );
            // Skipping cannot fail as recoverSet must contain end of file (EOF)
            skipTo( recoverSet );
        }
        debugLevel--;
        debugMessage( "End parse " + rule );
    }
    /** Output debugging message if debug turned on */
    private void debugMessage( String msg ) {
        if( debugParse ) {
            String indent = "";
            for( int i = 1; i <= debugLevel; i++ ) {
                indent += " ";
            }
            System.out.println( indent + msg );
        }
    }
   
    /**************************** Parsing Methods ***************************/

    /** RULE: Program -> Block ENDOFFILE */
    private Tree.ProgramNode parseProgram( ) {
        if( !beginRule( "Program", BLOCK_START_SET, EOF_SET ) ) {
            return null;
        }
        SymEntry.ProcedureEntry proc = 
            symtab.addProcedure( "<Main>", token.getPosn() );
        if( proc  == null ) {
            fatal( "Could not add main program to symbol table" );
        }
        proc.setLocalScope( symtab.newScope( proc ) );
        Tree.BlockNode block = parseBlock( EOF_SET );
        block.setProcEntry( proc );
        symtab.leaveScope();
        /* We can't use match because there is nothing following end of file */
        endRule( "Program", EOF_SET );
        return new Tree.ProgramNode( symtab, block );
    }
    /** RULE: Block -> { Declaration } CompoundStatement */
    private Tree.BlockNode parseBlock( TokenSet recoverSet ) {
        DeclNode.DeclListNode procedures = new DeclNode.DeclListNode();
        if( !beginRule("Block", BLOCK_START_SET, recoverSet)) {
            return new Tree.BlockNode( procedures, 
                    new StatementNode.ErrorNode( token.getPosn()) );
        }
        while( token.isIn( DECLARATION_START_SET ) ) {
            procedures = parseDeclaration( procedures, 
                        recoverSet.union( BLOCK_START_SET ) );
        }
        StatementNode statements = parseCompoundStatement( recoverSet );
        endRule( "Block", recoverSet );
        return new Tree.BlockNode( procedures, statements );
    }
    /** RULE:
     *  Declaration -> ConstDefList | TypeDefList | VarDeclList | ProcedureDef 
     */
    private DeclNode.DeclListNode parseDeclaration( 
            DeclNode.DeclListNode procedures, TokenSet recoverSet ) {
        beginRule( "Declarations", DECLARATION_START_SET ); /* cannot fail */
        if( token.isMatch( Token.KW_CONST ) ) {
            parseConstDefList( recoverSet.union( BLOCK_START_SET ) );
        } else if( token.isMatch( Token.KW_TYPE ) ) {
            parseTypeDefList( recoverSet.union( BLOCK_START_SET ) );
        } else if( token.isMatch( Token.KW_VAR ) ) {
            parseVarDeclList( recoverSet.union( BLOCK_START_SET ) );
        } else if( token.isMatch( Token.KW_PROCEDURE ) ) {
            DeclNode.ProcedureNode proc = 
                parseProcedureDef(recoverSet.union( BLOCK_START_SET));
            procedures.addDeclaration( proc );
        } else { // cannot get here
            fatal( "parseDeclaration", token );
        }
        endRule( "Block", recoverSet );
        return procedures;
    }
    /** Rule: ConstDefList -> KW_CONST ConstDef { ConstDef } */
    private void parseConstDefList( TokenSet recoverSet ) {
        beginRule( "Constant Definitions", Token.KW_CONST ); /* cannot fail */
        match( Token.KW_CONST );
        do {
            parseConstDef( recoverSet.union( Token.IDENTIFIER ) );
        } while( token.isMatch( Token.IDENTIFIER ) );
        endRule( "Constant Definitions", recoverSet );
    }
    /** Rule: ConstDef -> IDENTIFIER EQUALS Constant SEMICOLON */
    private void parseConstDef( TokenSet recoverSet ) {
        if( !beginRule("Constant Definition", Token.IDENTIFIER, recoverSet) ) {
            return;
        }
        /* token is an IDENTIFIER */
        LexicalToken constToken = token;
        match( Token.IDENTIFIER );
        match( Token.EQUALS, CONSTANT_START_SET );
        ConstExp tree = 
            parseConstant( recoverSet.union( Token.SEMICOLON ) );
        if( symtab.addConstant( constToken.getName(), constToken.getPosn(), 
                                    tree ) == null ) {
                error( "Constant identifier " + constToken.getName() + 
                    " already declared in this scope", constToken.getPosn() );
        }
        match( Token.SEMICOLON, recoverSet );
        endRule( "Constant Definition", recoverSet );
    }
    /** Rule: Constant -> NUMBER | IDENTIFIER | MINUS Constant */
    private ConstExp parseConstant( TokenSet recoverSet ) {
        // type of constant, defaults to ERROR_TYPE;
        ConstExp tree = new ConstExp.ErrorNode( token.getPosn(), 
                symtab.getCurrentScope() ); 
        if( !beginRule( "Constant", CONSTANT_START_SET, recoverSet ) ) {
            return tree;
        }
        if( token.isMatch( Token.NUMBER ) ) {
            tree = new ConstExp.NumberNode( token.getPosn(), 
                     symtab.getCurrentScope(), Type.INTEGER_TYPE, 
                     token.getIntValue() );
            match( Token.NUMBER );
        } else if( token.isMatch( Token.IDENTIFIER ) ) {
            tree = new ConstExp.ConstIdNode( token.getPosn(),
                    symtab.getCurrentScope(), token.getName());
            match( Token.IDENTIFIER );
        } else if( token.isMatch( Token.MINUS ) ) {
            Position pos = token.getPosn();
            match( Token.MINUS );
            tree = parseConstant( recoverSet );
            tree = new ConstExp.NegateNode( pos, 
                    symtab.getCurrentScope(), tree );
        }
        endRule( "Constant", recoverSet );
        return tree;
    }
    /** Rule: TypeDefList -> KW_TYPE TypeDef { TypeDef }  */
    private void parseTypeDefList( TokenSet recoverSet ) {
        beginRule( "Type Definitions", Token.KW_TYPE ); /* cannot fail */
        match( Token.KW_TYPE );
        do {
            parseTypeDef( recoverSet.union( Token.IDENTIFIER ) );
        } while( token.isMatch( Token.IDENTIFIER ) );
        endRule( "Type Definitions", recoverSet );
    }
    /** Rule: TypeDef -> IDENTIFIER EQUALS Type SEMICOLON */
    private void parseTypeDef( TokenSet recoverSet ) {
        if( !beginRule("Type Definition", Token.IDENTIFIER, recoverSet ) ) {
            return;
        }
        // token is an IDENTIFIER
        LexicalToken typeIdToken = token;
        match( Token.IDENTIFIER );
        match( Token.EQUALS, TYPE_START_SET );
        Type type = parseType( recoverSet.union( Token.SEMICOLON ) );
        if( symtab.addType(typeIdToken.getName(), 
                           typeIdToken.getPosn(), type) == null ){
            error( "Type identifier " + typeIdToken.getName() + 
                   " already declared in this scope", typeIdToken.getPosn() );
        }
        match( Token.SEMICOLON, recoverSet );
        endRule( "Type Definition", recoverSet );
    }
    /** Rule: Type -> TypeIdentifier | SubrangeType
     *        SubrangeType -> Constant RANGE Constant
     *  Because SubrangeType starts with a Constant, which can start
     *  with an IDENTIFIER, the above grammar is not suitable for
     *  recursive descent parsing. We left factor it and get
     *  the following grammar.
     *        Type -> IDENTIFIER [ RANGE Constant ] |
     *                Constant RANGE Constant
     *  Technically this grammar still has a left factor, but if we
     *  give precedence to the first alternative, it will suffice for
     *  recursive descent parsing.
     */
    private Type parseType( TokenSet recoverSet ) {
        ConstExp lower, upper;
        
        if( ! beginRule( "Type", TYPE_START_SET, recoverSet ) ) {
            return Type.ERROR_TYPE;
        }
        if( token.isMatch(Token.IDENTIFIER ) ) {
            String id = token.getName();
            Position pos = token.getPosn();
            match( Token.IDENTIFIER );
            if( ! token.isMatch( Token.RANGE ) ) {
                endRule( "Type", recoverSet );
                return new Type.IdRefType( id, symtab.getCurrentScope(), pos );
            }
            lower = new ConstExp.ConstIdNode( pos, symtab.getCurrentScope(),
                    id);
        } else {
            lower = parseConstant( recoverSet.union( Token.RANGE ) );
        }
        match( Token.RANGE, CONSTANT_START_SET );
        upper = parseConstant( recoverSet );
        Type type = 
            new Type.SubrangeType( symtab.getCurrentScope(), lower, upper );
        endRule( "Type", recoverSet );
        return type;
    }
    /** Rule: TypeIdentifier -> IDENTIFIER */
    private Type parseTypeIdentifier( TokenSet recoverSet ) {
        Type type = Type.ERROR_TYPE;
        if( ! beginRule( "TypeIdentifier", Token.IDENTIFIER, recoverSet ) ) {
            return type;
        }
        // must be an IDENTIFIER
        if( token.isMatch(Token.IDENTIFIER ) ) {
            String id = token.getName();
            Position pos = token.getPosn();
            type = new Type.IdRefType( id, symtab.getCurrentScope(), pos );
        }
        match( Token.IDENTIFIER, recoverSet );
        endRule( "TypeIdentifier", recoverSet );
        return type;
    }
    /** Rule: VarDeclList -> KW_VAR VarDecl { VarDecl }  */
    private void parseVarDeclList( TokenSet recoverSet ) {
        /* beginRule can't fail */
        beginRule( "Variable declarations", Token.KW_VAR, recoverSet );
        match( Token.KW_VAR );
        do {
            parseVarDecl( recoverSet.union( Token.IDENTIFIER ) );
        } while( token.isMatch( Token.IDENTIFIER ) ); 
        endRule( "Variable Declarations", recoverSet );
    }
    /** Rule: VarDecl -> IDENTIFIER COLON TypeIdentifier SEMICOLON */
    private void parseVarDecl( TokenSet recoverSet ) {
        if(!beginRule("Variable Declaration", Token.IDENTIFIER, recoverSet)) {
            return;
        }
        // token is an IDENTIFIER
        LexicalToken varToken = token;
        match( Token.IDENTIFIER );
        match( Token.COLON, TYPE_START_SET );
        Type type = parseTypeIdentifier( recoverSet.union( Token.SEMICOLON ) );
        // The type of a variable must be a reference type
        if( symtab.addVariable( varToken.getName(), varToken.getPosn(), 
                new Type.ReferenceType(type) ) == null ) {
            error( "Variable identifier " + varToken.getName() + 
                   " already declared in this scope", varToken.getPosn() );
        }
        match( Token.SEMICOLON, recoverSet );
        endRule( "Variable Declaration", recoverSet );
    }
    /** Rule: ProcedureDef -> ProcedureHead EQUALS Block SEMICOLON */
    private DeclNode.ProcedureNode parseProcedureDef( TokenSet recoverSet ) {
        /* beginRule can't fail */
        beginRule( "Procedure declaration", Token.KW_PROCEDURE );
        SymEntry.ProcedureEntry procEntry = parseProcedureHead( 
                recoverSet.union( Token.EQUALS ).union( BLOCK_START_SET ) );
        procEntry.setLocalScope( symtab.newScope( procEntry ) );
        match( Token.EQUALS, BLOCK_START_SET );
        Tree.BlockNode block = 
            parseBlock( recoverSet.union( Token.SEMICOLON) );
        block.setProcEntry( procEntry );
        symtab.leaveScope();
        match( Token.SEMICOLON, recoverSet );
        
        endRule( "Procedure Declaration", recoverSet );
        return new DeclNode.ProcedureNode( procEntry, block );
    }
    /** Rule: ProcedureHead -> KW_PROCEDURE IDENTIFIER LPAREN RPAREN */
    private SymEntry.ProcedureEntry parseProcedureHead(TokenSet recoverSet) {
        beginRule( "Procedure header", Token.KW_PROCEDURE ); /* cannot fail */
        SymEntry.ProcedureEntry procEntry;
        match( Token.KW_PROCEDURE );
        if( token.isMatch( Token.IDENTIFIER ) ) {
            procEntry = symtab.addProcedure( token.getName(), token.getPosn() );
            if( procEntry  == null ) {
                procEntry = new SymEntry.ProcedureEntry( token.getName(), 
                        token.getPosn(), symtab.getCurrentScope() );
                error( "Procedure identifier " + token.getName() +
                       " already declared in this scope" );
            }
            match( Token.IDENTIFIER );
        } else {
            error( "Identifier expected in procedure declaration" );
            procEntry = new SymEntry.ProcedureEntry("<undefined>", token.getPosn(), 
                    symtab.getCurrentScope() );
        }
        match( Token.LPAREN, Token.RPAREN );
        // parameters would go here
        match( Token.RPAREN, recoverSet );
        endRule( "Procedure header", recoverSet );
        return procEntry;
    }
    /** Rule: CompoundStatement -> BEGIN StatementList END  */
    private StatementNode parseCompoundStatement( TokenSet recoverSet ) {
        if( !beginRule( "Compound Statement", Token.KW_BEGIN, 
                   recoverSet.union( STATEMENT_START_SET ) ) ) {
            return new StatementNode.ListNode( token.getPosn() );
        }
        match( Token.KW_BEGIN, STATEMENT_START_SET );
        StatementNode result = 
            parseStatementList( recoverSet.union( Token.KW_END ));
        match( Token.KW_END, recoverSet );
        endRule( "Compound Statement", recoverSet );
        return result;
    }
    /** Rule: StatementList -> Statement { SEMICOLON Statement }  */
    private StatementNode parseStatementList( TokenSet recoverSet ) {
        // Initialize result to an empty list of statements
        StatementNode.ListNode result = 
                new StatementNode.ListNode( token.getPosn() );
        if( !beginRule( "StatementList", STATEMENT_START_SET,
                recoverSet.union(Token.SEMICOLON)) ) {
            return result;
        }
        StatementNode s = 
            parseStatement( recoverSet.union( Token.SEMICOLON ) );
        result.addStatement( s );
        
        while( token.isMatch( Token.SEMICOLON ) ) {
            match( Token.SEMICOLON );
            s = parseStatement( recoverSet.union( Token.SEMICOLON ) );
            result.addStatement( s );
        }
        endRule( "Statement list", recoverSet );
        return result;
    }
    /** Rule: Statement -> Assignment | WhileStatement | IfStatement
     *                  | ReadStatement | WriteStatement | CallStatement
     *                  | CompoundStatement | SkipStatement | DoStatement
     */
    private StatementNode parseStatement( TokenSet recoverSet ) {
        StatementNode result;
        if ( !beginRule( "Statement", STATEMENT_START_SET, recoverSet ) ) {
            return new StatementNode.ErrorNode( token.getPosn() );
        }
        switch( token.getKind() ) {
        case IDENTIFIER:
            result = parseAssignment( recoverSet ); 
            break;
        case KW_WHILE:
            result = parseWhileStatement( recoverSet ); 
            break;
        case KW_IF:
            result = parseIfStatement( recoverSet ); 
            break;
        case KW_READ:
            result = parseReadStatement( recoverSet ); 
            break;
        case KW_WRITE:
            result = parseWriteStatement( recoverSet ); 
            break;
        case KW_CALL:
            result = parseCallStatement( recoverSet ); 
            break;
        case KW_BEGIN:
            result = parseCompoundStatement( recoverSet ); 
            break;
        case KW_SKIP:
            result = parseSkipStatement( recoverSet );
            break;
        case KW_DO:
            result = parseDoStatement( recoverSet );
            break;
        default:
            fatal( "parse Statement " );
            result = new StatementNode.ErrorNode( token.getPosn() );
        }
        endRule( "Statement", recoverSet );
        return result;
    }
    /** Rule: DoStatement -> KW_DO DoBranch { SEPERATOR DoBranch } KW_OD */
    private StatementNode parseDoStatement(TokenSet recoverSet) {
        beginRule( "Do Statement", Token.KW_DO); // cannot fail
        Position pos = token.getPosn();
        StatementNode.DoStatementNode result = 
                new StatementNode.DoStatementNode( token.getPosn() );
        
        match( Token.KW_DO );
        
        StatementNode doBranch = parseDoBranch( recoverSet.union( Token.SEPARATOR ).union( Token.KW_OD ) );
        result.addDoBranch( (StatementNode.DoBranchNode) doBranch );
        
        while( token.isMatch( Token.SEPARATOR ) ) {
            match( Token.SEPARATOR );
            doBranch = parseDoBranch( recoverSet.union( Token.SEPARATOR ).union( Token.KW_OD) );
            result.addDoBranch( (StatementNode.DoBranchNode) doBranch );
        }
        
        match( Token.KW_OD );
        
        endRule( "Do Statement", recoverSet );
		return null;
	}
    /** Rule: DoBranch -> Condition KW_THEN StatementList [ KW_EXIT ] */ 
    private StatementNode parseDoBranch(TokenSet recoverSet) {
        if( !beginRule( "Do Branch", CONDITION_START_SET,
                recoverSet.union( Token.SEPARATOR ) ) ) {
        	return new StatementNode.ErrorNode( token.getPosn() );
        }
        
        Position pos = token.getPosn();
        Boolean isExit = false;
        
        ExpNode condition = parseCondition( recoverSet.union( Token.KW_THEN ) );
        match (Token.KW_THEN, STATEMENT_START_SET);
        
        StatementNode body = parseStatementList( recoverSet.union( Token.KW_EXIT ) );
        if ( token.isMatch( Token.KW_EXIT ) ) {
        	isExit = true;
        	match (Token.KW_EXIT);
        }
        
        StatementNode.DoBranchNode result = 
        		new StatementNode.DoBranchNode(pos, condition, body, isExit);
        
    	return result;
    }
	/** Rule: SkipStatement -> KW_SKIP */
    private StatementNode parseSkipStatement( TokenSet recoverSet ) {
        beginRule( "Skip Statement", Token.KW_SKIP ); // cannot fail
        Position pos = token.getPosn();
        match( Token.KW_SKIP );
        endRule( "Skip Statment", recoverSet );
		return new StatementNode.SkipNode( pos );
	}
	/** Rule: Assignment -> SingleAssignment { BAR SingleAssignment } */
    private StatementNode parseAssignment( TokenSet recoverSet ) {
        // Initialize result to an empty list of assignments
        if( !beginRule( "Assignment List", ASSIGNMENT_START_SET,
                recoverSet.union( Token.BAR ) ) ) {
        	return new StatementNode.ErrorNode( token.getPosn() );
        }
        
        StatementNode.AssignmentNode result = 
                new StatementNode.AssignmentNode( token.getPosn() );
        
        StatementNode s = 
            parseSingleAssignment( recoverSet.union( Token.BAR ) );
        result.addSingleAssign( (StatementNode.SingleAssignmentNode) s );
        
        while( token.isMatch( Token.BAR ) ) {
            match( Token.BAR );
            s = parseSingleAssignment( recoverSet.union( Token.BAR ) );
            result.addSingleAssign( (StatementNode.SingleAssignmentNode) s );
        }
        endRule( "Assignment List", recoverSet );
        return result;
    }
    
	/** Rule: SingleAssignment -> LValue ASSIGN Condition */
    private StatementNode parseSingleAssignment( TokenSet recoverSet ) {
        beginRule( "Single Assignment", LVALUE_START_SET ); // cannot fail
        ExpNode left = parseLValue( 
            recoverSet.union( Token.ASSIGN ).union(CONDITION_START_SET) );
        Position pos = token.getPosn();
        match( Token.ASSIGN, CONDITION_START_SET );
        ExpNode right = parseCondition( recoverSet );
        endRule( "Single Assignment", recoverSet );
        return new StatementNode.SingleAssignmentNode( pos, left, right );
    }
    /** Rule: WhileStatement -> KW_WHILE Condition KW_DO Statement */
    private StatementNode parseWhileStatement( TokenSet recoverSet ) {
        beginRule( "While Statement", Token.KW_WHILE ); // cannot fail
        Position pos = token.getPosn();
        match( Token.KW_WHILE );
        ExpNode cond = parseCondition( recoverSet.union( Token.KW_DO ) );
        match( Token.KW_DO, STATEMENT_START_SET );
        StatementNode statement = parseStatement( recoverSet );
        endRule( "While Statment", recoverSet );
        return new StatementNode.WhileNode( pos, cond, statement );
    }
    /** Rule: IfStatement -> KW_IF Condition KW_THEN Statement KW_ELSE Statement
     */
    private StatementNode parseIfStatement( TokenSet recoverSet ) {
        beginRule( "If Statement", Token.KW_IF ); // cannot fail
        match( Token.KW_IF );
        Position pos = token.getPosn();

        ExpNode cond = parseCondition( recoverSet.union( Token.KW_THEN ) );
        match( Token.KW_THEN, STATEMENT_START_SET );
        StatementNode thenClause = 
            parseStatement( recoverSet.union( Token.KW_ELSE ) );
        match( Token.KW_ELSE, STATEMENT_START_SET );
        StatementNode elseClause = parseStatement( recoverSet );

        endRule( "If Statement", recoverSet );
        return new StatementNode.IfNode( pos, cond, thenClause, elseClause );
    }
    /** Rule: ReadStatement -> KW_READ LValue */
    private StatementNode parseReadStatement( TokenSet recoverSet ) {
        beginRule( "Read Statement", Token.KW_READ ); // cannot fail
        match( Token.KW_READ );
        Position pos = token.getPosn();

        ExpNode lval = parseLValue( recoverSet );
        endRule( "Read Statement", recoverSet );
        // A read statement is treated as an assignment of the value read
        // to the variable. A ReadNode is an expression.
        return new StatementNode.SingleAssignmentNode( pos, lval, 
                        new ExpNode.ReadNode( pos ) );
    }
    /** Rule: WriteStatement -> KW_WRITE Exp */
    private StatementNode parseWriteStatement( TokenSet recoverSet ) {
        beginRule( "Write Statement", Token.KW_WRITE ); // cannot fail
        match( Token.KW_WRITE );
        Position pos = token.getPosn();
        
        ExpNode exp = parseExp( recoverSet );
        endRule( "Write Statement", recoverSet );
        return new StatementNode.WriteNode( pos, exp );
    }
    /** Rule: CallStatement -> KW_CALL IDENTIFIER LPAREN RPAREN */
    private StatementNode parseCallStatement( TokenSet recoverSet ) {
        beginRule( "Call Statement", Token.KW_CALL ); // cannot fail
        match( Token.KW_CALL );
        Position pos = token.getPosn();
        String procId;
        if( token.isMatch( Token.IDENTIFIER ) ) {
            procId = token.getName();
        } else {
            procId = "<noid>";
        }
        match( Token.IDENTIFIER, Token.LPAREN );
        match( Token.LPAREN, Token.RPAREN );
        // actual parameters would go here
        match( Token.RPAREN, recoverSet );
        endRule( "Call Statement", recoverSet );
        return new StatementNode.CallNode( pos, procId 
                );
    }
    /** Rule: Condition -> Exp [ RelOp Exp ] */
    private ExpNode parseCondition( TokenSet recoverSet ) {
        if( !beginRule( "Condition", CONDITION_START_SET, recoverSet ) ) {
            return new ExpNode.ErrorNode( token.getPosn() );
        }
        ExpNode cond = parseExp( recoverSet.union( REL_OPS_SET ) );
        if( token.isIn( REL_OPS_SET ) ) {
            Position pos = token.getPosn();
            BinaryOperator operatorCode = 
                parseRelOp( recoverSet.union( EXP_START_SET ) );
            ExpNode right = parseExp( recoverSet );
            cond = new ExpNode.BinaryOpNode( pos, operatorCode, 
                                           cond, right );
        }
        endRule( "Condition", recoverSet );
        return cond;
    }
    /** Rule: RelOp -> EQUALS | NEQUALS | LEQUALS | LESS | GREATER | GEQUALS */
    private BinaryOperator parseRelOp( TokenSet recoverSet ) {
        beginRule( "RelOp", REL_OPS_SET ); // cannot fail
        BinaryOperator operatorCode = BinaryOperator.INVALID_OP;
        switch( token.getKind() ) {
        case EQUALS:
            operatorCode = BinaryOperator.EQUALS_OP;
            match( Token.EQUALS );
            break;
        case NEQUALS:
            operatorCode = BinaryOperator.NEQUALS_OP;
            match( Token.NEQUALS );
            break;
        case LESS:
            operatorCode = BinaryOperator.LESS_OP;
            match( Token.LESS );
            break;
        case GREATER:
            operatorCode = BinaryOperator.GREATER_OP; 
            match( Token.GREATER );
            break;
        case LEQUALS:
            operatorCode = BinaryOperator.LEQUALS_OP;
            match( Token.LEQUALS );
            break;
        case GEQUALS:
            operatorCode = BinaryOperator.GEQUALS_OP;
            match( Token.GEQUALS );
            break;
        default:
            fatal( "Unreachable branch in parseCondition" );
        }
        endRule( "RelOp", recoverSet );
        return operatorCode;
    }
    /** Rule: Exp -> [ PLUS | MINUS ] Term { ( PLUS | MINUS ) Term } */
    private ExpNode parseExp( TokenSet recoverSet ) {
        if( !beginRule( "Expression", EXP_START_SET, recoverSet ) ) {
            return new ExpNode.ErrorNode( token.getPosn() );
        }
        boolean haveUnaryMinus = false;
        Position pos = token.getPosn();
        if( token.isMatch( Token.MINUS ) ) {
            haveUnaryMinus = true;
            match( Token.MINUS );
        } else if( token.isMatch( Token.PLUS ) ) {
            match( Token.PLUS );
        }
        ExpNode exp = parseTerm( recoverSet.union( EXP_OPS_SET ) );
        if( haveUnaryMinus ) {
            exp = new ExpNode.UnaryOpNode( pos, UnaryOperator.NEG_OP, exp );
        }
        while( token.isIn( EXP_OPS_SET ) ) {
            BinaryOperator operatorCode = BinaryOperator.INVALID_OP;
            pos = token.getPosn();
            if ( token.isMatch( Token.MINUS ) ) {
                operatorCode = BinaryOperator.SUB_OP;
                match( Token.MINUS );
            } else if ( token.isMatch( Token.PLUS ) ) {
                operatorCode = BinaryOperator.ADD_OP;
                match( Token.PLUS );
            } else {
                fatal( "Unreachable branch in parseExp" );
            }
            ExpNode right = parseTerm( recoverSet.union( EXP_OPS_SET ) );
            exp = new ExpNode.BinaryOpNode( pos, operatorCode, exp, right );
        }
        endRule( "Expression", recoverSet );
        return exp;
    }
    /** Rule: Term  -> Factor { ( TIMES | DIVIDE ) Factor }  */
    private ExpNode parseTerm( TokenSet recoverSet ) {
        if( !beginRule( "Term", TERM_START_SET, recoverSet ) ) {
            return new  ExpNode.ErrorNode( token.getPosn() );
        }
        ExpNode term = parseFactor( recoverSet.union( TERM_OPS_SET ) );
        while( token.isIn( TERM_OPS_SET ) ) {
            BinaryOperator operatorCode = BinaryOperator.INVALID_OP;
            Position pos = token.getPosn();
            if ( token.isMatch( Token.TIMES ) ) {
                operatorCode = BinaryOperator.MUL_OP;
                match( Token.TIMES );
            } else if ( token.isMatch( Token.DIVIDE ) ) {
                operatorCode = BinaryOperator.DIV_OP;
                match( Token.DIVIDE );
            } else {
                fatal( "Unreachable branch in parseTerm" );
            }
            ExpNode right = parseFactor( recoverSet.union( TERM_OPS_SET ) );
            term = new ExpNode.BinaryOpNode( pos, operatorCode, term, right );
        }
        endRule( "Term", recoverSet );
        return term;
    }
    /** Rule: Factor -> LPAREN Condition RPAREN | NUMBER | LValue  */
    private ExpNode parseFactor( TokenSet recoverSet ) {
        if( !beginRule( "Factor", FACTOR_START_SET, recoverSet ) ) {
            return new ExpNode.ErrorNode( token.getPosn() );
        }
        ExpNode result;
        if( token.isMatch( Token.IDENTIFIER ) ) {
            result = parseLValue( recoverSet );
        } else if( token.isMatch( Token.NUMBER ) ) {
            result = new ExpNode.ConstNode( token.getPosn(), Type.INTEGER_TYPE,
                                         token.getIntValue() );
            match( Token.NUMBER );
        } else if( token.isMatch( Token.LPAREN ) ) {
            match( Token.LPAREN );
            result = parseCondition( recoverSet.union( Token.RPAREN ) );
            match( Token.RPAREN, recoverSet );
        } else {
            result = null;  // initialise to keep Java happy
            fatal( "Unreachable branch in Factor" );
        }
        endRule( "Factor", recoverSet );
        return result;
    }
    /** Rule: LValue -> IDENTIFIER */
    private ExpNode parseLValue( TokenSet recoverSet ) {
        if( !beginRule( "LValue", Token.IDENTIFIER, recoverSet ) ) {
            return new ExpNode.ErrorNode( token.getPosn() );
        }
        ExpNode result = 
            new ExpNode.IdentifierNode( token.getPosn(), token.getName() );
        match( Token.IDENTIFIER );
        endRule( "LValue", recoverSet );
        return result;
    }

/*********************** Private convenience Methods ************************/
    /** Assert that condition is true. Otherwise throw an error which should
     * abort the compiler immediately
     */
    private void pl0_assert( boolean condition, String m ) {
        if( !condition ) fatal( "Assertion failed! " + m );
    }
    /** Signal an error at the current token */
    private void error( String m ) {
        errors.errorMessage( m, Severity.ERROR, token.getPosn() );
    }
    /** Signal an error at the given position */
    private void error( String m, Position pos ) {
        errors.errorMessage( m, Severity.ERROR, pos );
    }
    /** Signal a fatal error at the current token */
    private void fatal( String m ) {
        errors.errorMessage( m, Severity.FATAL, token.getPosn() );
    }
    /** Signal a fatal error at the given token */
    private void fatal( String m, LexicalToken tok ) {
        errors.errorMessage( m, Severity.FATAL, tok.getPosn() );
    }
}
